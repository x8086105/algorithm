阿里：
问：10亿个数中如何高效地找到最大的一个数以及最大的第 K 个数？

答1:如果是int类型的话，每个数字占4个字节，40亿字节的话占用内存大概有3810M左右。4G的内存空间，
对于一些可用内存小于4G的计算机而言，肯定不能一下将数据全部加载到内存进行处理了。假设能够放到内存中
进行处理的话，如果使用内存进行直接排序，算法不同，时间复杂度也会不一样，最好的也是O(nlogN).如快速排序
效率也不会很高。

答2:用一个双向链表先把前面第K个数从大到小排列起来，然后遍历剩余的元素，每次将需要对比的下个元素跟目前链表中最小的元素
和最大的元素进行比较，如果大于最小的元素，则移除队尾的元素，将该元素插入到队列中（还是要保证有序），如果大于最大元素，则
加到对头，并且移除队尾元素。并且移除队尾的元素之后添加的新元素要保证顺序性，移除的时间复杂度是O(1)，但是插入的时候，最差的
时间复杂度是O（n）。等到所有元素遍历完之后，这个容器中的头跟尾就是想要的元素。

答3:分治法
将10亿个数等分成1000份，每份有100万个数，找到每份中的最大的K个数。每份中通过快速排序的方式，将数据分为2堆，如果大堆里的数据
超过K个数，就会在进行分堆，如果还超过，继续，直到不超过了，就从小堆中拿到大堆中的前（K-大堆数量的）个数。这样，每份的就有了。
然后在两两进行合并，拿到k个数，依旧使用快排的思想，等所有的数据变成1分数据，这一份就是想要的数据

答4:hash算法进行去重。然后如果重复率高的话，那数据就会减少很多，然后进行上述三个方法进行排序即可。

答5:采用最小堆，首先读入前K个元素创建的堆，建堆的时间复杂度为O（mlogm）然后遍历后续的数字，并于堆顶（最小）数字进行比较。
如果比最小的数小，则继续读取后续数字；如果比堆顶数字大，则替换堆顶元素并重新调整堆为最小堆。整个过程直至10亿个数全部遍历完为止。
然后按照中序遍历的方式输出当前堆中的所有K个数字。该算法的时间复杂度为O（nmlogm），空间复杂度是K（常数）。


问：给两个文件，分别有100亿个URL，我们只有1G内存，如何找到两个文件交集？
分析
1G内存为10亿字节，所以无法把100亿直接载入内存，所以我们可以通过哈希与位图的结合来处理该问题。先哈希到位图上，在把俩个位图按位与求其交集。
假如每个url大小为10bytes，那么可以估计每个文件的大小为50G×64=320G，远远大于内存限制的4G，所以不可能将其完全加载到内存中处理，
可以采用分治的思想来解决。

　　Step1：遍历文件a，对每个url求取hash(url)%1000，然后根据所取得的值将url分别存储到1000个小文件(记为a0,a1,...,a999，
每个小文件约300M);

　　Step2:遍历文件b，采取和a相同的方式将url分别存储到1000个小文件(记为b0,b1,...,b999);

　　巧妙之处：这样处理后，所有可能相同的url都被保存在对应的小文件(a0vsb0,a1vsb1,...,a999vsb999)中，
不对应的小文件不可能有相同的url。然后我们只要求出这个1000对小文件中相同的url即可。

　　Step3：求每对小文件ai和bi中相同的url时，可以把ai的url存储到hash_set/hash_map中。然后遍历bi的每个url，
看其是否在刚才构建的hash_set中，如果是，那么就是共同的url，存到文件里面就可以了。

